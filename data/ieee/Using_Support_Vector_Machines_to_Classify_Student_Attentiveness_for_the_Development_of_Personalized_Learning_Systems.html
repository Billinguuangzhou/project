<?xml version="1.0" encoding="UTF-8"?>
<div id="BodyWrapper" class="ArticlePage" xmlns:ieee="http://www.ieeexplore.ieee.org"><div id="article">
<div class="section" id="sec1"><div class="header article-hdr"><div class="kicker">
		                        SECTION I.</div><h2>Introduction</h2></div><p>Many studies have been performed to determine the attentiveness of students in an instructional setting. Many of these studies relied on qualitative techniques rather than a quantitative approach to identifying and measuring attentiveness <a ref-type="bibr" anchor="ref1" id="context_ref_1_1">[1]</a>, <a ref-type="bibr" anchor="ref2" id="context_ref_2_1">[2]</a>, <a ref-type="bibr" anchor="ref3" id="context_ref_3_1">[3]</a>. Some researchers have also investigated quantitative approaches to monitoring student attentiveness. Biometric bracelets are being investigated as an indicator of student attentiveness <a ref-type="bibr" anchor="ref4" id="context_ref_4_1">[4]</a>. Eye and head pose tracking have also been used to determine student attentiveness <a ref-type="bibr" anchor="ref5" id="context_ref_5_1">[5]</a>. Facial expressions have been used to infer student attentiveness for computer network courses <a ref-type="bibr" anchor="ref6" id="context_ref_6_1">[6]</a>.</p><p>Classifying students as attentive or inattentive can be helpful to the instructor by providing feedback as to which teaching style a particular student responds most favorably to. There are four learning orientations a learner will likely fall into: an innovator; an implementer; a sustainer; or a resistant learner <a ref-type="bibr" anchor="ref7" id="context_ref_7_1">[7]</a>. If an instructor is able to classify a student as attentive or inattentive when the student is exposed to the associated teaching styles of each of these orientations, students can be separated into course sections that implement their optimal learning style or can be assigned online teaching modules that use the teaching style a particular student will perform optimally with.</p><p>Researchers have developed personalized e-learning systems based on Genetic algorithms (GA) and case-based reasoning (CBR) <a ref-type="bibr" anchor="ref8" id="context_ref_8_1">[8]</a>. Adaptive user interfaces have also been developed based on personalized learning <a ref-type="bibr" anchor="ref9" id="context_ref_9_1">[9]</a>. These approaches focus on online learning settings. The proposed system in this research can be applied to online as well as classroom instructional settings.</p><p>This article describes a system that uses a commercial RGB-D camera to monitor, count, and record student gestures, postures, facial expressions, and verbalizations in order to produce data for determining student attentiveness. Machine learning algorithms are then used to cluster, label, and classify the data for the purpose of classifying subsequent students as attentive or inattentive. This system is an imperative step towards developing the proposed personalized learning system described in this article.</p></div>
<div class="section" id="sec2"><div class="header article-hdr"><div class="kicker">
		                        SECTION II.</div><h2>Methodology</h2></div><p><a ref-type="fig" anchor="fig1" class="fulltext-link">Figure 1</a> illustrates the system proposed in this article. First, an RGB-D sensor is used to observe a single student. An algorithm that is running in real time then detects and counts various behaviors that indicate attentiveness. These data for this student are stored into a database. When every student in the study has been observed, the data from the database are clustered into two groups using the K-means algorithm <a ref-type="bibr" anchor="ref10" id="context_ref_10_2">[10]</a>. After the data are clustered and then labeled as attentive or inattentive, the SVM algorithm <a ref-type="bibr" anchor="ref11" id="context_ref_11_2">[11]</a> is used to create a decision boundary for the two groups of data.
<div class="figure figure-full" id="fig1"><!--
          Workaround for combined images.Eg.- 1000116 Fig. 5
        --><div class="img-wrap"><a href="/mediastore_new/IEEE/content/media/6784147/6784569/6784636/6784636-fig-1-source-large.gif"><img src="/mediastore_new/IEEE/content/media/6784147/6784569/6784636/6784636-fig-1-source-small.gif" alt="Figure 1"/><div class="zoom" title="View Larger Image"/></a></div><div class="figcaption"><b class="title">Figure 1: </b><fig>System Overview</fig></div><p class="links"><a href="/document/6784636/all-figures" class="all">View All</a></p></div>
</p><div class="section_2" id="sec2a"><h3>A. RGB-D Sensor</h3><p>In this system, an RGB-D sensor would be used to detect various student behaviors. We propose the use of a Kinect sensor <a ref-type="bibr" anchor="ref12" id="context_ref_12_2a">[12]</a> since it is a relatively inexpensive consumer RGB-D sensor with many capabilities built into its official software development kit (SDK). An example of a Kinect application used for this purpose is shown in <a ref-type="fig" anchor="fig2" class="fulltext-link">Figure 2</a>. An algorithm that detects, counts, and records the number of times a student raises his or her hand was developed using the Kinect sensor and its associated SDK.</p></div><div class="section_2" id="sec2b"><h3>B. Behavior-detecting Algorithm</h3><p>There are various behaviors that indicate attentiveness; and many of these can be automatically observed and recorded using an RGB-D camera. Some examples of these types of behaviors are: leaning forward <a ref-type="bibr" anchor="ref13" id="context_ref_13_2b">[13]</a>; speaking to the instructor; hand raising; eyebrow raising / lowering <a ref-type="bibr" anchor="ref14" id="context_ref_14_2b">[14]</a>.</p></div><div class="section_2" id="sec2c"><h3>C. Database</h3><p>The data of each student are saved into the database separately; since each RGB-D sensor is used for one student. After each student is observed and the instructional session is over, the data are recorded into a new row inside of the database. The number of occurrences of each feature (e.g. hand raising or leaning forward) is stored into a different column of that row.</p></div><div class="section_2" id="sec2d"><h3>D. Data Clustering</h3><p>When every student in the study has been observed, the data are clustered into two clusters using the K-means algorithm. The clusters of data are labeled as attentive or inattentive depending on the distance from the origin of the data; the cluster with a centroid closest to the origin is labeled inattentive and the other cluster is labeled attentive. This is done since all of the recorded data indicate attentive behavior and a lack of these behaviors results in the centroid of that cluster being closer to the origin of the dataset.</p></div><div class="section_2" id="sec2e"><h3>E. Classification Algoritm</h3><p>Since the clusters are now labeled, a supervised learning algorithm can be used to create a decision boundary. In this work, we used the support vector machine (SVM) algorithm. Six of the data points were used for training and the remaining fourteen were used for testing.</p></div></div>
<div class="section" id="sec3"><div class="header article-hdr"><div class="kicker">
		                        SECTION III.</div><h2>Experiments</h2></div><div class="section_2" id="sec3a"><h3>A. Data Generation</h3><p>The data used in this analysis were created by randomly generating data within a fixed range of values (from zero to twelve); these values represented the number of times a student was observed exhibiting a specific attentiveness behavior. For illustration purposes, each hypothetical student was given only two features (attentiveness behavior) each: number of hand raises; and number of times eyebrows were raised. <a ref-type="fig" anchor="fig3" class="fulltext-link">Figure 3</a> depicts the generated data. Each of the points in the figure represent a separate student. Twenty hypothetical students were used in this study.</p></div><div class="section_2" id="sec3b"><h3>B. K-means Algorithm</h3><p>The K-means algorithm was used to cluster the data. <a ref-type="algorithm" anchor="alg1" class="fulltext-link">Algorithm 1</a> illustrates the basic procedure of the algorithm. In this research, the algorithm converged in four iterations as illustrated in <a ref-type="fig" anchor="fig4" class="fulltext-link">Figure 4</a>.</p></div><div class="section_2" id="sec3c"><h3>C. Support Vector Machine Algorithm</h3><p>After the data were clustered and labeled using the K-means algorithm, they were classified using the SVM algorithm. <a ref-type="algorithm" anchor="alg2" class="fulltext-link">Algorithm 2</a> illustrates the basic algorithm. The variable <inline-formula id=""><tex-math notation="TeX">\$\Theta\$</tex-math></inline-formula> represents the parameters and <inline-formula id=""><tex-math notation="TeX">\$f\$</tex-math></inline-formula> is chosen based on the type of kernel function used. In this research, a Gaussian Kernel was chosen.
<div class="figure figure-full" id="fig2"><!--
          Workaround for combined images.Eg.- 1000116 Fig. 5
        --><div class="img-wrap"><a href="/mediastore_new/IEEE/content/media/6784147/6784569/6784636/6784636-fig-2-source-large.gif"><img src="/mediastore_new/IEEE/content/media/6784147/6784569/6784636/6784636-fig-2-source-small.gif" alt="Figure 2"/><div class="zoom" title="View Larger Image"/></a></div><div class="figcaption"><b class="title">Figure 2: </b><fig>Hand Raise Counter Application</fig></div><p class="links"><a href="/document/6784636/all-figures" class="all">View All</a></p></div>
<div class="figure figure-full" id="fig3"><!--
          Workaround for combined images.Eg.- 1000116 Fig. 5
        --><div class="img-wrap"><a href="/mediastore_new/IEEE/content/media/6784147/6784569/6784636/6784636-fig-3-source-large.gif"><img src="/mediastore_new/IEEE/content/media/6784147/6784569/6784636/6784636-fig-3-source-small.gif" alt="Figure 3"/><div class="zoom" title="View Larger Image"/></a></div><div class="figcaption"><b class="title">Figure 3: </b><fig>Plot of simulated student behaviors</fig></div><p class="links"><a href="/document/6784636/all-figures" class="all">View All</a></p></div>
<div class="figure figure-full" id="fig4"><!--
          Workaround for combined images.Eg.- 1000116 Fig. 5
        --><div class="img-wrap"><a href="/mediastore_new/IEEE/content/media/6784147/6784569/6784636/6784636-fig-4-source-large.gif"><img src="/mediastore_new/IEEE/content/media/6784147/6784569/6784636/6784636-fig-4-source-small.gif" alt="Figure 4"/><div class="zoom" title="View Larger Image"/></a></div><div class="figcaption"><b class="title">Figure 4: </b><fig>Result of K-means clustering</fig></div><p class="links"><a href="/document/6784636/all-figures" class="all">View All</a></p></div>
</p></div></div>
<div class="section" id="sec4"><div class="header article-hdr"><div class="kicker">
		                        SECTION IV.</div><h2>Results</h2></div><p>The data were clustered using the K-means algorithm and classified using the SVM algorithm. <a ref-type="fig" anchor="fig5" class="fulltext-link">Figure 5</a> illustrates the final classification and the associated decision boundary for the group of hypothetical students.</p><p>From these results, students who were not included in the initial training or testing set can be observed and automatically classified as attentive or inattentive based on the clustering and classification of the students in a given study. In a real-world application of this system, more students would be considered and the researcher would need to ensure that the students are representative of the demographic of students he or she is attempting to automatically classify <a ref-type="bibr" anchor="ref15" id="context_ref_15_4">[15]</a>.</p></div>
<div class="section" id="sec5"><div class="header article-hdr"><div class="kicker">
		                        SECTION V.</div><h2>Conclusion</h2></div><p>This research lays the groundwork for building a system that can automatically classify a student as attentive or inattentive in an instructional setting. In this study, data were generated that represented students' number of hand raises and number of eyebrow raises during an instructional session. It was proposed that this data should be collected using a commercial RGB-D camera such as the Kinect sensor.</p><p>The generated data was then clustered into two groups and labeled as attentive or inattentive. These labeled data were then used as training and testing data in a supervised learning algorithm (SVM) to establish a decision boundary. This decision boundary can then be used to automatically classify subsequent students as attentive or inattentive.</p><p>In this research we only used two features, but this concept can be extended to many additional features. The data were limited in this article for illustration purposes.</p><p>The results from the system can be used to determine the learning style of a particular student. An instructor can teach similar material with various teaching styles and record which particular student reacts best to a given style. When the optimal teaching style is found for a specific student, that student can be placed in an instructional setting that exclusively uses that style. This would provide the student with personalized learning and could increase the likelihood of the student's classroom success.</p><div class="algorithm" id="alg1"><div class="header article-hdr"><div class="kicker">
		                        SECTION Algorithm 1</div><h2>K-means Algorithm</h2></div>
<p>
</p>
<div class="figure"><div class="img-wrap"><a href="/mediastore_new/IEEE/content/media/6784147/6784569/6784636/6784636-alg-1-source-large.gif"><img src="/mediastore_new/IEEE/content/media/6784147/6784569/6784636/6784636-alg-1-source-small.gif" alt="Algorithm "/><div class="zoom" title="View Larger Image"/></a></div></div></div><div class="algorithm" id="alg2"><div class="header article-hdr"><div class="kicker">
		                        SECTION Algorithm 2</div><h2>SVM Algorithm</h2></div>
<p>
</p>
<div class="figure"><div class="img-wrap"><a href="/mediastore_new/IEEE/content/media/6784147/6784569/6784636/6784636-alg-2-source-large.gif"><img src="/mediastore_new/IEEE/content/media/6784147/6784569/6784636/6784636-alg-2-source-small.gif" alt="Algorithm "/><div class="zoom" title="View Larger Image"/></a></div></div></div><div class="figure figure-full" id="fig5"><!--
          Workaround for combined images.Eg.- 1000116 Fig. 5
        --><div class="img-wrap"><a href="/mediastore_new/IEEE/content/media/6784147/6784569/6784636/6784636-fig-5-source-large.gif"><img src="/mediastore_new/IEEE/content/media/6784147/6784569/6784636/6784636-fig-5-source-small.gif" alt="Figure 5"/><div class="zoom" title="View Larger Image"/></a></div><div class="figcaption"><b class="title">Figure 5: </b><fig>Result of applying SVM to labeled data</fig></div><p class="links"><a href="/document/6784636/all-figures" class="all">View All</a></p></div></div>
<h3>Acknowledgement</h3><p><ul style="list-style-type:disc"><li><p>Title III HBGI Program</p></li></ul></p></div></div>
